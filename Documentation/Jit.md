## JIT Documentation 

#### Overview 
Just In Time (JIT) compilation means that the code is generated during program execution. Sometimes this is before a given method is run the first time; sometimes the method runs a few times to gather information about the execution.

We choose for the default to be threaded code. A threaded method has its first "word" (pointer to machine-executable code) be a word that will verify the selector and then jump to the next threaded word.

If a method is jit'ed or built-in, the first word will point to the jit'ed or built-in code directly, and it will be responsible for verifying the selector before proceeding.

#### Details


#### Importing Pharo code
We want to be able to use the methods that are sitting in the Pharo image to run for Zag instead of rewriting every one from scratch. 

Pharo has an AST for each of its methods. It is substantially more complex AST than Zag uses, so the first step is to convert it to a Zag AST.

We export Pharo methods in two forms, both converted from Zag ASTs into Zig code.
1. the raw AST objects, generated as calls to `compileObject` which generate statically-allocated memory objects;
2. threaded-compiled methods, generated as calls to `compiledMethod` which generate statically-allocated `CompiledMethod` objects - ready to be executed.

Zag then takes the stringified version of the tree and converts it to a tree that maps to the original Pharo AST. This is what would be called the Zag AST (ASC)  

The Zag AST later gets converted into a compile method (linearized version?). These compile methods later get stored into the Zag image (runtime). 

When an object in Zag gets sent a message that fails to be found in the dispatch table for the object's class and its parent/super classes, then we send a DNU message.   

Each time a specific compiled method is invoked during execution, its verify selector instruction is updated (increased). The verify selector instruction acts as a counter to determine if the compile method is a good candidate for being JIT â€™ed. The idea is that methods that have been observed to be repetitively executed, have a higher chance of continuing the trend of repeated execution. The regions in a codebase that contain a high proportion of executed instructions or where most time is spent during the program's execution is called a hotspot. We wish to optimize these hotspots by JIT'ing them as it allows us to compile (with LLVM) and optimize them with runtime information. This in turn greatly improves application performance.    

If a method is invoked after it has been JIT'd, then, we execute its stored machine code generated by LLVM.   

My Task: I am not generating the CPS code - rather, I am simply taking the compiled method code and converting that into LLVM IR. The resulting machine code is later stored somewhere (confirm where). 

#### Questions  

> Will remove these later once answered

- You mentioned during our last meeting that the `compileMethods` linearizes the AST and then sends it over to the Zag runtime. I thought that the Pharo AST was converted to a string representation and then sent over to the Zag runtime? 

    Also, you mention that the `compileMethods` takes the Zag AST as input later on.  
    
    Do the `compileMethods` exist in both the Smalltalk & Zag environment then? A bit confused about the actual role of the `compiledMethods`.  

#### Links 

- [an LLVM-Zig repo](https://github.com/kassane/llvm-zig/tree/main)
- The JIT uses [Execution](Execution.md#Method%20dispatch)
- Eclipse-OMR, [Eclipse-OMR](https://eclipse-omr.org)
- OpenJIT, [openjit.org](https://www.openjit.org/)
- [LLVM IR](https://llvm.org/docs/Reference.html#llvm-ir) [Reference Manual](https://llvm.org/docs/LangRef.html#syntax) [Turorials](https://llvm.org/docs/GettingStartedTutorials.html)
- [LLVM getelementptr](https://llvm.org/docs/GetElementPtr.html)
